# import pandas library
import pandas as pd
import numpy as np


file_path='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/auto.csv'

We utilize the pandas.read_csv() function for reading CSV files. However, in this version of the lab, which operates on JupyterLite, the dataset needs to be downloaded to the interface using the provided code below.

This dataset was hosted on IBM Cloud object. Click HERE for free storage.

The functions below will download the dataset into your browser:

from pyodide.http import pyfetch

async def download(url, filename):
    response = await pyfetch(url)
    if response.status == 200:
        with open(filename, "wb") as f:
            f.write(await response.bytes())

To obtain the dataset, utilize the download() function as defined above:

await download(file_path, "auto.csv")
file_name="auto.csv"

Utilize the Pandas method read_csv() to load the data into a dataframe.

df = pd.read_csv(file_name)

After reading the data set, we can use the data_frame.head(n) method to check the top n rows of the data frame, where n is an integer. Contrary to data_frame.head(n), data_frame.tail(n) will show you the bottom n rows of the data frame.

# show the first 5 rows using dataframe.head() method
print("The first 5 rows of the dataframe") 
df.head(5)

Question #1: Â¶
Check the bottom 10 rows of data frame "df".

df.tail(10)

First, create a list "headers" that include all column names in order. Then, use dataframe.columns = headers to replace the headers with the list you created.

# create headers list
headers = ["symboling","normalized-losses","make","fuel-type","aspiration", "num-of-doors","body-style",
         "drive-wheels","engine-location","wheel-base", "length","width","height","curb-weight","engine-type",
         "num-of-cylinders", "engine-size","fuel-system","bore","stroke","compression-ratio","horsepower",
         "peak-rpm","city-mpg","highway-mpg","price"]
print("headers\n", headers)

Replace headers and recheck our data frame:
df.columns = headers
df.columns

You can also see the first 10 entries of the updated data frame and note that the headers are updated.
df.head(10)

Now, we need to replace the "?" symbol with NaN so the dropna() can remove the missing values:
df1=df.replace('?',np.NaN)

You can drop missing values along the column "price" as follows:
df=df1.dropna(subset=["price"], axis=0)
df.head(20)

Here, axis=0 means that the contents along the entire row will be dropped wherever the entity 'price' is found to be NaN

Now, you have successfully read the raw data set and added the correct headers into the data frame.

Find the name of the columns of the dataframe.
print (df.columns)

SAVE DATASET
Correspondingly, Pandas enables you to save the data set to CSV. By using the dataframe.to_csv() method, you can add the file path and name along with quotation marks in the brackets.

df.to_csv("automobile.csv", index=False)

data types
df.dtypes

# check the data type of data frame "df" by .dtypes
print(df.dtypes)

Describe
This method will provide various summary statistics, excluding NaN (Not a Number) values.
df.describe()

# describe all the columns in "df" 
df.describe(include = "all")

Question #3: 
You can select the columns of a dataframe by indicating the name of each column. For example, you can select the three columns as follows:

dataframe[[' column 1 ',column 2', 'column 3']]

Where "column" is the name of the column, you can apply the method ".describe()" to get the statistics of those columns as follows:

dataframe[[' column 1 ',column 2', 'column 3'] ].describe()

Apply the method to ".describe()" to the columns 'length' and 'compression-ratio'.

df[['length', 'compression-ratio']].describe()

info
dataframe.info()

It provides a concise summary of your data frame.

This method prints information about a data frame including the index dtype and columns, non-null values and memory usage.

# look at the info of "df"
df.info()
